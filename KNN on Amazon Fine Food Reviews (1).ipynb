{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from string import punctuation\n",
    "from sklearn import svm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from itertools import chain\n",
    "from time import time\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline \n",
    "import pickle\n",
    "def savetofile(obj,filename):\n",
    "    pickle.dump(obj,open(filename+\".p\",\"wb\"), protocol=4)\n",
    "def openfromfile(filename):\n",
    "    temp = pickle.load(open(filename+\".p\",\"rb\"))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Original Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('desktop/Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568449</td>\n",
       "      <td>568450</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>Lettie D. Carter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1299628800</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568450</td>\n",
       "      <td>568451</td>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>R. Sawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1331251200</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568451</td>\n",
       "      <td>568452</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>pksd \"pk_007\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568452</td>\n",
       "      <td>568453</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>Kathy A. Welch \"katwel\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1331596800</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568453</td>\n",
       "      <td>568454</td>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>srfell17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                      ProfileName  \\\n",
       "0            1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1            2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2            3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3            4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4            5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "...        ...         ...             ...                              ...   \n",
       "568449  568450  B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
       "568450  568451  B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
       "568451  568452  B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
       "568452  568453  B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
       "568453  568454  B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                          1                       1      5  1303862400   \n",
       "1                          0                       0      1  1346976000   \n",
       "2                          1                       1      4  1219017600   \n",
       "3                          3                       3      2  1307923200   \n",
       "4                          0                       0      5  1350777600   \n",
       "...                      ...                     ...    ...         ...   \n",
       "568449                     0                       0      5  1299628800   \n",
       "568450                     0                       0      2  1331251200   \n",
       "568451                     2                       2      5  1329782400   \n",
       "568452                     1                       1      5  1331596800   \n",
       "568453                     0                       0      5  1338422400   \n",
       "\n",
       "                                   Summary  \\\n",
       "0                    Good Quality Dog Food   \n",
       "1                        Not as Advertised   \n",
       "2                    \"Delight\" says it all   \n",
       "3                           Cough Medicine   \n",
       "4                              Great taffy   \n",
       "...                                    ...   \n",
       "568449                 Will not do without   \n",
       "568450                        disappointed   \n",
       "568451            Perfect for our maltipoo   \n",
       "568452  Favorite Training and reward treat   \n",
       "568453                         Great Honey   \n",
       "\n",
       "                                                     Text  \n",
       "0       I have bought several of the Vitality canned d...  \n",
       "1       Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2       This is a confection that has been around a fe...  \n",
       "3       If you are looking for the secret ingredient i...  \n",
       "4       Great taffy at a great price.  There was a wid...  \n",
       "...                                                   ...  \n",
       "568449  Great for sesame chicken..this is a good if no...  \n",
       "568450  I'm disappointed with the flavor. The chocolat...  \n",
       "568451  These stars are small, so you can give 10-15 o...  \n",
       "568452  These are the BEST treats for training and rew...  \n",
       "568453  I am very satisfied ,product is as advertised,...  \n",
       "\n",
       "[568454 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the cleaned and processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.read_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>CleanedText_NoStem</th>\n",
       "      <th>CleanedSummary</th>\n",
       "      <th>Combined_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>bought sever vital can dog food product found ...</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good qualiti dog food</td>\n",
       "      <td>bought sever vital can dog food product found ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>not advertis</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>confect around centuri light pillowi citrus ge...</td>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight say all</td>\n",
       "      <td>confect around centuri light pillowi citrus ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>look secret ingredi robitussin believ found go...</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicin</td>\n",
       "      <td>look secret ingredi robitussin believ found go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>great taffi great price wide assort yummi taff...</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffi</td>\n",
       "      <td>great taffi great price wide assort yummi taff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364166</td>\n",
       "      <td>568449</td>\n",
       "      <td>568450</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>Lettie D. Carter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1299628800</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>great sesam chicken good not better restur eat...</td>\n",
       "      <td>great sesame chicken good not better resturant...</td>\n",
       "      <td>will not without</td>\n",
       "      <td>great sesam chicken good not better restur eat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364167</td>\n",
       "      <td>568450</td>\n",
       "      <td>568451</td>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>R. Sawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1331251200</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>disappoint flavor chocol note especi weak milk...</td>\n",
       "      <td>disappointed flavor chocolate notes especially...</td>\n",
       "      <td>disappoint</td>\n",
       "      <td>disappoint flavor chocol note especi weak milk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364168</td>\n",
       "      <td>568451</td>\n",
       "      <td>568452</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>pksd \"pk_007\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>star small give one train session tri train do...</td>\n",
       "      <td>stars small give one training session tried tr...</td>\n",
       "      <td>perfect for our maltipoo</td>\n",
       "      <td>star small give one train session tri train do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364169</td>\n",
       "      <td>568452</td>\n",
       "      <td>568453</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>Kathy A. Welch \"katwel\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1331596800</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>best treat train reward dog good groom lower c...</td>\n",
       "      <td>best treats training rewarding dog good groomi...</td>\n",
       "      <td>favorit train and reward treat</td>\n",
       "      <td>best treat train reward dog good groom lower c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364170</td>\n",
       "      <td>568453</td>\n",
       "      <td>568454</td>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>srfell17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>satisfi product advertis use cereal raw vinega...</td>\n",
       "      <td>satisfied product advertised use cereal raw vi...</td>\n",
       "      <td>great honey</td>\n",
       "      <td>satisfi product advertis use cereal raw vinega...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364171 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      Id   ProductId          UserId  \\\n",
       "0                0       1  B001E4KFG0  A3SGXH7AUHU8GW   \n",
       "1                1       2  B00813GRG4  A1D87F6ZCVE5NK   \n",
       "2                2       3  B000LQOCH0   ABXLMWJIXXAIN   \n",
       "3                3       4  B000UA0QIQ  A395BORC6FGVXV   \n",
       "4                4       5  B006K2ZZ7K  A1UQRSCLF8GW1T   \n",
       "...            ...     ...         ...             ...   \n",
       "364166      568449  568450  B001EO7N10  A28KG5XORO54AY   \n",
       "364167      568450  568451  B003S1WTCU  A3I8AFVPEE8KI5   \n",
       "364168      568451  568452  B004I613EE  A121AA1GQV751Z   \n",
       "364169      568452  568453  B004I613EE   A3IBEVCTXKNOH   \n",
       "364170      568453  568454  B001LR2CU2  A3LGQPJCZVL9UC   \n",
       "\n",
       "                            ProfileName  HelpfulnessNumerator  \\\n",
       "0                            delmartian                     1   \n",
       "1                                dll pa                     0   \n",
       "2       Natalia Corres \"Natalia Corres\"                     1   \n",
       "3                                  Karl                     3   \n",
       "4         Michael D. Bigham \"M. Wassir\"                     0   \n",
       "...                                 ...                   ...   \n",
       "364166                 Lettie D. Carter                     0   \n",
       "364167                        R. Sawyer                     0   \n",
       "364168                    pksd \"pk_007\"                     2   \n",
       "364169          Kathy A. Welch \"katwel\"                     1   \n",
       "364170                         srfell17                     0   \n",
       "\n",
       "        HelpfulnessDenominator  Score        Time  \\\n",
       "0                            1      5  1303862400   \n",
       "1                            0      1  1346976000   \n",
       "2                            1      4  1219017600   \n",
       "3                            3      2  1307923200   \n",
       "4                            0      5  1350777600   \n",
       "...                        ...    ...         ...   \n",
       "364166                       0      5  1299628800   \n",
       "364167                       0      2  1331251200   \n",
       "364168                       2      5  1329782400   \n",
       "364169                       1      5  1331596800   \n",
       "364170                       0      5  1338422400   \n",
       "\n",
       "                                   Summary  \\\n",
       "0                    Good Quality Dog Food   \n",
       "1                        Not as Advertised   \n",
       "2                    \"Delight\" says it all   \n",
       "3                           Cough Medicine   \n",
       "4                              Great taffy   \n",
       "...                                    ...   \n",
       "364166                 Will not do without   \n",
       "364167                        disappointed   \n",
       "364168            Perfect for our maltipoo   \n",
       "364169  Favorite Training and reward treat   \n",
       "364170                         Great Honey   \n",
       "\n",
       "                                                     Text SentimentPolarity  \\\n",
       "0       I have bought several of the Vitality canned d...          Positive   \n",
       "1       Product arrived labeled as Jumbo Salted Peanut...          Negative   \n",
       "2       This is a confection that has been around a fe...          Positive   \n",
       "3       If you are looking for the secret ingredient i...          Negative   \n",
       "4       Great taffy at a great price.  There was a wid...          Positive   \n",
       "...                                                   ...               ...   \n",
       "364166  Great for sesame chicken..this is a good if no...          Positive   \n",
       "364167  I'm disappointed with the flavor. The chocolat...          Negative   \n",
       "364168  These stars are small, so you can give 10-15 o...          Positive   \n",
       "364169  These are the BEST treats for training and rew...          Positive   \n",
       "364170  I am very satisfied ,product is as advertised,...          Positive   \n",
       "\n",
       "        Class_Labels                                        CleanedText  \\\n",
       "0                  1  bought sever vital can dog food product found ...   \n",
       "1                  0  product arriv label jumbo salt peanut peanut a...   \n",
       "2                  1  confect around centuri light pillowi citrus ge...   \n",
       "3                  0  look secret ingredi robitussin believ found go...   \n",
       "4                  1  great taffi great price wide assort yummi taff...   \n",
       "...              ...                                                ...   \n",
       "364166             1  great sesam chicken good not better restur eat...   \n",
       "364167             0  disappoint flavor chocol note especi weak milk...   \n",
       "364168             1  star small give one train session tri train do...   \n",
       "364169             1  best treat train reward dog good groom lower c...   \n",
       "364170             1  satisfi product advertis use cereal raw vinega...   \n",
       "\n",
       "                                       CleanedText_NoStem  \\\n",
       "0       bought several vitality canned dog food produc...   \n",
       "1       product arrived labeled jumbo salted peanuts p...   \n",
       "2       confection around centuries light pillowy citr...   \n",
       "3       looking secret ingredient robitussin believe f...   \n",
       "4       great taffy great price wide assortment yummy ...   \n",
       "...                                                   ...   \n",
       "364166  great sesame chicken good not better resturant...   \n",
       "364167  disappointed flavor chocolate notes especially...   \n",
       "364168  stars small give one training session tried tr...   \n",
       "364169  best treats training rewarding dog good groomi...   \n",
       "364170  satisfied product advertised use cereal raw vi...   \n",
       "\n",
       "                        CleanedSummary  \\\n",
       "0                good qualiti dog food   \n",
       "1                         not advertis   \n",
       "2                      delight say all   \n",
       "3                        cough medicin   \n",
       "4                          great taffi   \n",
       "...                                ...   \n",
       "364166                will not without   \n",
       "364167                      disappoint   \n",
       "364168        perfect for our maltipoo   \n",
       "364169  favorit train and reward treat   \n",
       "364170                     great honey   \n",
       "\n",
       "                                         Combined_Reviews  \n",
       "0       bought sever vital can dog food product found ...  \n",
       "1       product arriv label jumbo salt peanut peanut a...  \n",
       "2       confect around centuri light pillowi citrus ge...  \n",
       "3       look secret ingredi robitussin believ found go...  \n",
       "4       great taffi great price wide assort yummi taff...  \n",
       "...                                                   ...  \n",
       "364166  great sesam chicken good not better restur eat...  \n",
       "364167  disappoint flavor chocol note especi weak milk...  \n",
       "364168  star small give one train session tri train do...  \n",
       "364169  best treat train reward dog good groom lower c...  \n",
       "364170  satisfi product advertis use cereal raw vinega...  \n",
       "\n",
       "[364171 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Class_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>364171.000000</td>\n",
       "      <td>364171.000000</td>\n",
       "      <td>364171.000000</td>\n",
       "      <td>364171.000000</td>\n",
       "      <td>364171.000000</td>\n",
       "      <td>3.641710e+05</td>\n",
       "      <td>364171.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>261813.561014</td>\n",
       "      <td>261814.561014</td>\n",
       "      <td>1.739021</td>\n",
       "      <td>2.186841</td>\n",
       "      <td>4.275796</td>\n",
       "      <td>1.296135e+09</td>\n",
       "      <td>0.843178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>166958.768333</td>\n",
       "      <td>166958.768333</td>\n",
       "      <td>6.723921</td>\n",
       "      <td>7.348482</td>\n",
       "      <td>1.318650</td>\n",
       "      <td>4.864772e+07</td>\n",
       "      <td>0.363633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.393408e+08</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>113378.500000</td>\n",
       "      <td>113379.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.270858e+09</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>249444.000000</td>\n",
       "      <td>249445.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.311379e+09</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>407407.500000</td>\n",
       "      <td>407408.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.332893e+09</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>568453.000000</td>\n",
       "      <td>568454.000000</td>\n",
       "      <td>866.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.351210e+09</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0             Id  HelpfulnessNumerator  \\\n",
       "count  364171.000000  364171.000000         364171.000000   \n",
       "mean   261813.561014  261814.561014              1.739021   \n",
       "std    166958.768333  166958.768333              6.723921   \n",
       "min         0.000000       1.000000              0.000000   \n",
       "25%    113378.500000  113379.500000              0.000000   \n",
       "50%    249444.000000  249445.000000              0.000000   \n",
       "75%    407407.500000  407408.500000              2.000000   \n",
       "max    568453.000000  568454.000000            866.000000   \n",
       "\n",
       "       HelpfulnessDenominator          Score          Time   Class_Labels  \n",
       "count           364171.000000  364171.000000  3.641710e+05  364171.000000  \n",
       "mean                 2.186841       4.275796  1.296135e+09       0.843178  \n",
       "std                  7.348482       1.318650  4.864772e+07       0.363633  \n",
       "min                  0.000000       1.000000  9.393408e+08       0.000000  \n",
       "25%                  0.000000       4.000000  1.270858e+09       1.000000  \n",
       "50%                  1.000000       5.000000  1.311379e+09       1.000000  \n",
       "75%                  2.000000       5.000000  1.332893e+09       1.000000  \n",
       "max                878.000000       5.000000  1.351210e+09       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364171"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.shape\n",
    "final_data['Score'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>CleanedText_NoStem</th>\n",
       "      <th>CleanedSummary</th>\n",
       "      <th>Combined_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>bought sever vital can dog food product found ...</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good qualiti dog food</td>\n",
       "      <td>bought sever vital can dog food product found ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>not advertis</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>confect around centuri light pillowi citrus ge...</td>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight say all</td>\n",
       "      <td>confect around centuri light pillowi citrus ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>look secret ingredi robitussin believ found go...</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicin</td>\n",
       "      <td>look secret ingredi robitussin believ found go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>great taffi great price wide assort yummi taff...</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffi</td>\n",
       "      <td>great taffi great price wide assort yummi taff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Id   ProductId          UserId  \\\n",
       "0           0   1  B001E4KFG0  A3SGXH7AUHU8GW   \n",
       "1           1   2  B00813GRG4  A1D87F6ZCVE5NK   \n",
       "2           2   3  B000LQOCH0   ABXLMWJIXXAIN   \n",
       "3           3   4  B000UA0QIQ  A395BORC6FGVXV   \n",
       "4           4   5  B006K2ZZ7K  A1UQRSCLF8GW1T   \n",
       "\n",
       "                       ProfileName  HelpfulnessNumerator  \\\n",
       "0                       delmartian                     1   \n",
       "1                           dll pa                     0   \n",
       "2  Natalia Corres \"Natalia Corres\"                     1   \n",
       "3                             Karl                     3   \n",
       "4    Michael D. Bigham \"M. Wassir\"                     0   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time                Summary  \\\n",
       "0                       1      1  1303862400  Good Quality Dog Food   \n",
       "1                       0      1  1346976000      Not as Advertised   \n",
       "2                       1      1  1219017600  \"Delight\" says it all   \n",
       "3                       3      1  1307923200         Cough Medicine   \n",
       "4                       0      1  1350777600            Great taffy   \n",
       "\n",
       "                                                Text SentimentPolarity  \\\n",
       "0  I have bought several of the Vitality canned d...          Positive   \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...          Negative   \n",
       "2  This is a confection that has been around a fe...          Positive   \n",
       "3  If you are looking for the secret ingredient i...          Negative   \n",
       "4  Great taffy at a great price.  There was a wid...          Positive   \n",
       "\n",
       "   Class_Labels                                        CleanedText  \\\n",
       "0             1  bought sever vital can dog food product found ...   \n",
       "1             0  product arriv label jumbo salt peanut peanut a...   \n",
       "2             1  confect around centuri light pillowi citrus ge...   \n",
       "3             0  look secret ingredi robitussin believ found go...   \n",
       "4             1  great taffi great price wide assort yummi taff...   \n",
       "\n",
       "                                  CleanedText_NoStem         CleanedSummary  \\\n",
       "0  bought several vitality canned dog food produc...  good qualiti dog food   \n",
       "1  product arrived labeled jumbo salted peanuts p...           not advertis   \n",
       "2  confection around centuries light pillowy citr...        delight say all   \n",
       "3  looking secret ingredient robitussin believe f...          cough medicin   \n",
       "4  great taffy great price wide assortment yummy ...            great taffi   \n",
       "\n",
       "                                    Combined_Reviews  \n",
       "0  bought sever vital can dog food product found ...  \n",
       "1  product arriv label jumbo salt peanut peanut a...  \n",
       "2  confect around centuri light pillowi citrus ge...  \n",
       "3  look secret ingredi robitussin believ found go...  \n",
       "4  great taffi great price wide assort yummi taff...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def polarity(x):\n",
    "    if x == \"Positive\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "final_data[\"Score\"] = final_data[\"Score\"].map(polarity) #Map all the scores as the function polarity i.e. positive or negative\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>CleanedText_NoStem</th>\n",
       "      <th>CleanedSummary</th>\n",
       "      <th>Combined_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>63317</td>\n",
       "      <td>76881</td>\n",
       "      <td>76882</td>\n",
       "      <td>B00002N8SM</td>\n",
       "      <td>A32DW342WBJ6BX</td>\n",
       "      <td>Buttersugar</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>948672000</td>\n",
       "      <td>A sure death for flies</td>\n",
       "      <td>I bought a few of these after my apartment was...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>bought apart infest fruit fli hour trap quot a...</td>\n",
       "      <td>bought apartment infested fruit flies hours tr...</td>\n",
       "      <td>sure death for fli</td>\n",
       "      <td>bought apart infest fruit fli hour trap quot a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169367</td>\n",
       "      <td>230375</td>\n",
       "      <td>230376</td>\n",
       "      <td>B00004RYGX</td>\n",
       "      <td>ACJR7EQF9S6FP</td>\n",
       "      <td>Jeremy Robertson</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>951523200</td>\n",
       "      <td>Bettlejuice...Bettlejuice...BETTLEJUICE!</td>\n",
       "      <td>What happens when you say his name three times...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>happen say name three time michael keaten star...</td>\n",
       "      <td>happens say name three times michael keaten st...</td>\n",
       "      <td>bettlejuic bettlejuic bettlejuic</td>\n",
       "      <td>happen say name three time michael keaten star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169263</td>\n",
       "      <td>230264</td>\n",
       "      <td>230265</td>\n",
       "      <td>B00004RYGX</td>\n",
       "      <td>AZRJH4JFB59VC</td>\n",
       "      <td>Lynwood E. Hines</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>997228800</td>\n",
       "      <td>Great movie, terrible DVD</td>\n",
       "      <td>I am continually amazed at the shoddy treatmen...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>continu amaz shoddi treatment movi get dvd rel...</td>\n",
       "      <td>continually amazed shoddy treatment movies get...</td>\n",
       "      <td>great movi terribl dvd</td>\n",
       "      <td>continu amaz shoddi treatment movi get dvd rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316046</td>\n",
       "      <td>479722</td>\n",
       "      <td>479723</td>\n",
       "      <td>B00005U2FA</td>\n",
       "      <td>A3TO9GEQEGKFDC</td>\n",
       "      <td>N. Smith \"emerald999\"</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1020211200</td>\n",
       "      <td>I love this thing</td>\n",
       "      <td>The wine saver is great in so many ways. Obvio...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>wine saver great mani way obvious wonder abl o...</td>\n",
       "      <td>wine saver great many ways obviously wonderful...</td>\n",
       "      <td>love this thing</td>\n",
       "      <td>wine saver great mani way obvious wonder abl o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169331</td>\n",
       "      <td>230336</td>\n",
       "      <td>230337</td>\n",
       "      <td>B00004RYGX</td>\n",
       "      <td>A1CAA94EOP0J2S</td>\n",
       "      <td>Travis J Smith</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1036022400</td>\n",
       "      <td>Great Comedy</td>\n",
       "      <td>Beetlejuice is the story of ghosts (Alec Baldw...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>beetlejuic stori ghost alec baldwin geena davi...</td>\n",
       "      <td>beetlejuice story ghosts alec baldwin geena da...</td>\n",
       "      <td>great comedi</td>\n",
       "      <td>beetlejuic stori ghost alec baldwin geena davi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158412</td>\n",
       "      <td>213675</td>\n",
       "      <td>213676</td>\n",
       "      <td>B0000D9MXU</td>\n",
       "      <td>A3MXE8CDJX12V2</td>\n",
       "      <td>L. M. Schulz \"domestic engineer\"</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1067644800</td>\n",
       "      <td>A Cheese the Whole Family Likes...</td>\n",
       "      <td>The description of a cross between cheddar and...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>descript cross cheddar parmesan complet accur ...</td>\n",
       "      <td>description cross cheddar parmesan completely ...</td>\n",
       "      <td>chees the whole famili like</td>\n",
       "      <td>descript cross cheddar parmesan complet accur ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232022</td>\n",
       "      <td>330847</td>\n",
       "      <td>330848</td>\n",
       "      <td>B0000CH4FX</td>\n",
       "      <td>A2D1KU0E3W608M</td>\n",
       "      <td>\"nhenschel4\"</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1068595200</td>\n",
       "      <td>addicting!!</td>\n",
       "      <td>If you like Earl Grey tea, you'll find no bett...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>like earl grey tea find better harney amp son ...</td>\n",
       "      <td>like earl grey tea find better harney amp son ...</td>\n",
       "      <td>addict</td>\n",
       "      <td>like earl grey tea find better harney amp son ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128150</td>\n",
       "      <td>165712</td>\n",
       "      <td>165713</td>\n",
       "      <td>B0000D9N59</td>\n",
       "      <td>A3FE2GUBM8JZ3G</td>\n",
       "      <td>TestMagic Inc.</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1073088000</td>\n",
       "      <td>One of the great cheeses of the world</td>\n",
       "      <td>The only real Parmigiano (Reggiano) is one of ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>real parmigiano reggiano one great chees world...</td>\n",
       "      <td>real parmigiano reggiano one great cheeses wor...</td>\n",
       "      <td>one the great chees the world</td>\n",
       "      <td>real parmigiano reggiano one great chees world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135968</td>\n",
       "      <td>176943</td>\n",
       "      <td>176944</td>\n",
       "      <td>B0000CNU7C</td>\n",
       "      <td>A1KSJOHCUJCK2U</td>\n",
       "      <td>stu21202 \"phallophile\"</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1073865600</td>\n",
       "      <td>It's curry-tastic!!!</td>\n",
       "      <td>I have been a fan of S&amp;amp;B Golden Curry sinc...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>fan amp golden curri sinc found box japantown ...</td>\n",
       "      <td>fan amp golden curry since found box japantown...</td>\n",
       "      <td>curri tastic</td>\n",
       "      <td>fan amp golden curri sinc found box japantown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170682</td>\n",
       "      <td>232263</td>\n",
       "      <td>232264</td>\n",
       "      <td>B0000DG58Q</td>\n",
       "      <td>AY81BBSXD7T3W</td>\n",
       "      <td>Michele</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1074470400</td>\n",
       "      <td>PICKAPEPPA</td>\n",
       "      <td>For many years I tried various meat sauces: Am...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>mani year tri various meat sauc american engli...</td>\n",
       "      <td>many years tried various meat sauces american ...</td>\n",
       "      <td>pickapeppa</td>\n",
       "      <td>mani year tri various meat sauc american engli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      Id   ProductId          UserId  \\\n",
       "63317        76881   76882  B00002N8SM  A32DW342WBJ6BX   \n",
       "169367      230375  230376  B00004RYGX   ACJR7EQF9S6FP   \n",
       "169263      230264  230265  B00004RYGX   AZRJH4JFB59VC   \n",
       "316046      479722  479723  B00005U2FA  A3TO9GEQEGKFDC   \n",
       "169331      230336  230337  B00004RYGX  A1CAA94EOP0J2S   \n",
       "158412      213675  213676  B0000D9MXU  A3MXE8CDJX12V2   \n",
       "232022      330847  330848  B0000CH4FX  A2D1KU0E3W608M   \n",
       "128150      165712  165713  B0000D9N59  A3FE2GUBM8JZ3G   \n",
       "135968      176943  176944  B0000CNU7C  A1KSJOHCUJCK2U   \n",
       "170682      232263  232264  B0000DG58Q   AY81BBSXD7T3W   \n",
       "\n",
       "                             ProfileName  HelpfulnessNumerator  \\\n",
       "63317                        Buttersugar                     0   \n",
       "169367                  Jeremy Robertson                     2   \n",
       "169263                  Lynwood E. Hines                    21   \n",
       "316046             N. Smith \"emerald999\"                    35   \n",
       "169331                    Travis J Smith                     4   \n",
       "158412  L. M. Schulz \"domestic engineer\"                     3   \n",
       "232022                      \"nhenschel4\"                     4   \n",
       "128150                    TestMagic Inc.                    26   \n",
       "135968            stu21202 \"phallophile\"                     4   \n",
       "170682                           Michele                     0   \n",
       "\n",
       "        HelpfulnessDenominator  Score        Time  \\\n",
       "63317                        0      1   948672000   \n",
       "169367                       3      1   951523200   \n",
       "169263                      23      1   997228800   \n",
       "316046                      35      1  1020211200   \n",
       "169331                       4      1  1036022400   \n",
       "158412                       3      1  1067644800   \n",
       "232022                       5      1  1068595200   \n",
       "128150                      31      1  1073088000   \n",
       "135968                       4      1  1073865600   \n",
       "170682                       0      1  1074470400   \n",
       "\n",
       "                                         Summary  \\\n",
       "63317                     A sure death for flies   \n",
       "169367  Bettlejuice...Bettlejuice...BETTLEJUICE!   \n",
       "169263                 Great movie, terrible DVD   \n",
       "316046                         I love this thing   \n",
       "169331                              Great Comedy   \n",
       "158412        A Cheese the Whole Family Likes...   \n",
       "232022                               addicting!!   \n",
       "128150     One of the great cheeses of the world   \n",
       "135968                      It's curry-tastic!!!   \n",
       "170682                                PICKAPEPPA   \n",
       "\n",
       "                                                     Text SentimentPolarity  \\\n",
       "63317   I bought a few of these after my apartment was...          Positive   \n",
       "169367  What happens when you say his name three times...          Positive   \n",
       "169263  I am continually amazed at the shoddy treatmen...          Negative   \n",
       "316046  The wine saver is great in so many ways. Obvio...          Positive   \n",
       "169331  Beetlejuice is the story of ghosts (Alec Baldw...          Positive   \n",
       "158412  The description of a cross between cheddar and...          Positive   \n",
       "232022  If you like Earl Grey tea, you'll find no bett...          Positive   \n",
       "128150  The only real Parmigiano (Reggiano) is one of ...          Positive   \n",
       "135968  I have been a fan of S&amp;B Golden Curry sinc...          Positive   \n",
       "170682  For many years I tried various meat sauces: Am...          Positive   \n",
       "\n",
       "        Class_Labels                                        CleanedText  \\\n",
       "63317              1  bought apart infest fruit fli hour trap quot a...   \n",
       "169367             1  happen say name three time michael keaten star...   \n",
       "169263             0  continu amaz shoddi treatment movi get dvd rel...   \n",
       "316046             1  wine saver great mani way obvious wonder abl o...   \n",
       "169331             1  beetlejuic stori ghost alec baldwin geena davi...   \n",
       "158412             1  descript cross cheddar parmesan complet accur ...   \n",
       "232022             1  like earl grey tea find better harney amp son ...   \n",
       "128150             1  real parmigiano reggiano one great chees world...   \n",
       "135968             1  fan amp golden curri sinc found box japantown ...   \n",
       "170682             1  mani year tri various meat sauc american engli...   \n",
       "\n",
       "                                       CleanedText_NoStem  \\\n",
       "63317   bought apartment infested fruit flies hours tr...   \n",
       "169367  happens say name three times michael keaten st...   \n",
       "169263  continually amazed shoddy treatment movies get...   \n",
       "316046  wine saver great many ways obviously wonderful...   \n",
       "169331  beetlejuice story ghosts alec baldwin geena da...   \n",
       "158412  description cross cheddar parmesan completely ...   \n",
       "232022  like earl grey tea find better harney amp son ...   \n",
       "128150  real parmigiano reggiano one great cheeses wor...   \n",
       "135968  fan amp golden curry since found box japantown...   \n",
       "170682  many years tried various meat sauces american ...   \n",
       "\n",
       "                          CleanedSummary  \\\n",
       "63317                 sure death for fli   \n",
       "169367  bettlejuic bettlejuic bettlejuic   \n",
       "169263            great movi terribl dvd   \n",
       "316046                   love this thing   \n",
       "169331                      great comedi   \n",
       "158412       chees the whole famili like   \n",
       "232022                            addict   \n",
       "128150     one the great chees the world   \n",
       "135968                      curri tastic   \n",
       "170682                        pickapeppa   \n",
       "\n",
       "                                         Combined_Reviews  \n",
       "63317   bought apart infest fruit fli hour trap quot a...  \n",
       "169367  happen say name three time michael keaten star...  \n",
       "169263  continu amaz shoddi treatment movi get dvd rel...  \n",
       "316046  wine saver great mani way obvious wonder abl o...  \n",
       "169331  beetlejuic stori ghost alec baldwin geena davi...  \n",
       "158412  descript cross cheddar parmesan complet accur ...  \n",
       "232022  like earl grey tea find better harney amp son ...  \n",
       "128150  real parmigiano reggiano one great chees world...  \n",
       "135968  fan amp golden curri sinc found box japantown ...  \n",
       "170682  mani year tri various meat sauc american engli...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Taking Sample Data\n",
    "n_samples = 25000\n",
    "df_sample = final_data.sample(n_samples)\n",
    "\n",
    "###Sorting as we want according to time series\n",
    "df_sample.sort_values('Time',inplace=True) \n",
    "df_sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving 25000 samples in disk to as to test to test on the same sample for each of all Algo\n",
    "savetofile(df_sample,\"sample_25000_knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening from samples from file\n",
    "df_sample = openfromfile(\"sample_25000_knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Models using Different Featurization in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words (BoW)\n",
    "A commonly used model in methods of Text Classification. As part of the BOW model, a piece of text (sentence or a document) is represented as a bag or multiset of words, disregarding grammar and even word order and the frequency or occurrence of each word is used as a feature for training a classifier.\n",
    "OR\n",
    "Simply,converting a collection of text documents to a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Size:  (17500, 17026)\n",
      "Test Data Size:  (7500, 17026)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Breaking into Train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_sample['CleanedText'].values,df_sample['Score'].values,test_size=0.3,shuffle=False)\n",
    "\n",
    "#Text -> Uni gram Vectors\n",
    "uni_gram = CountVectorizer() \n",
    "X_train = uni_gram.fit_transform(X_train)\n",
    "#Normalize Data\n",
    "X_train = preprocessing.normalize(X_train)\n",
    "print(\"Train Data Size: \",X_train.shape)\n",
    "X_test = uni_gram.transform(X_test)\n",
    "#Normalize Data\n",
    "X_test = preprocessing.normalize(X_test)\n",
    "print(\"Test Data Size: \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 17026) (1590, 17026)\n",
      "(3190, 17026) (1590, 17026)\n",
      "(4780, 17026) (1590, 17026)\n",
      "(6370, 17026) (1590, 17026)\n",
      "(7960, 17026) (1590, 17026)\n",
      "(9550, 17026) (1590, 17026)\n",
      "(11140, 17026) (1590, 17026)\n",
      "(12730, 17026) (1590, 17026)\n",
      "(14320, 17026) (1590, 17026)\n",
      "(15910, 17026) (1590, 17026)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "for train, cv in tscv.split(X_train):\n",
    "#     print(\"%s %s\" % (train, cv))\n",
    "    print(X_train[train].shape, X_train[cv].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best 'k' value using Forward Chaining Cross Validation or Time Series CV\n",
    "## 1. Without Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 41s\n",
      "Parser   : 133 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#No of splits for Forward Chaining Cross Validation\n",
    "n_splits = 10  \n",
    "#Max no. of neighbours for KNN\n",
    "neigh_max = 100\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "#To store accuracy of different k values\n",
    "k_acc = []\n",
    "\n",
    "for k in range(1,neigh_max,2):\n",
    "    #To store accuracy of different fold\n",
    "    acc_list = []\n",
    "    for train, cv in tscv.split(X_train):\n",
    "          if(train.size > k): \n",
    "            knn = KNeighborsClassifier(n_neighbors=k,algorithm='brute',n_jobs=-1)\n",
    "            knn.fit(X_train[train],y_train[train])\n",
    "            acc_list.append(knn.score(X_train[cv],y_train[cv])*100)\n",
    "    if(acc_list):        \n",
    "        acc_nparr = np.array(acc_list) \n",
    "    k_acc.append(acc_nparr.mean())\n",
    "k_acc = np.array(k_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "savetofile(k_acc,\"k_acc_uni_gram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100.,\n",
       "       100., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100.,\n",
       "       100., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100.,\n",
       "       100., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100.,\n",
       "       100., 100., 100., 100., 100., 100.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_acc_uni_gram = openfromfile(\"k_acc_uni_gram\")\n",
    "k_acc_uni_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(np.arange(1,100,2),k_acc_uni_gram)\n",
    "plt.xlabel(\"K Nearest Neighbours\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy for different k values on uni_gram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With k=11-13 uni_gram has the highest accuracy of 86%\n",
    "As we can see after a no. of neighbours the accuracy dips hence the no. of neighbours is restricted to 100 neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. With Grid Search CV\n",
    "The above code for finding best value of 'k' can be condensed using Grid Search CV it tries all the possible params which tell it to try on and returns the best params and best accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.Brute Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(algorithm='brute')\n",
    "# neigh = np.arange(1,100,2)\n",
    "param_grid = {'n_neighbors':np.arange(1,100,2)} #params we need to try on classifier\n",
    "tscv = TimeSeriesSplit(n_splits=10) #For time based splitting\n",
    "gsv = GridSearchCV(knn,param_grid,cv=tscv,verbose=1)\n",
    "gsv.fit(X_train,y_train)\n",
    "print(\"Best HyperParameter: \",gsv.best_params_)\n",
    "print(\"Best Accuracy: %.2f%%\"%(gsv.best_score_*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Accuracy on Test data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\n",
    "print(\"Precision on test set: %0.3f\"%(precision_score(y_test, y_pred)))\n",
    "print(\"Recall on test set: %0.3f\"%(recall_score(y_test, y_pred)))\n",
    "print(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix of test set:\\n [ [TN  FP]\\n [FN TP] ]\\n\")\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Kd tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(algorithm='kd_tree')\n",
    "# neigh = np.arange(1,100,2)\n",
    "param_grid = {'n_neighbors':np.arange(1,100,2)} #params we need to try on classifier\n",
    "tscv = TimeSeriesSplit(n_splits=10) #For time based splitting\n",
    "gsv = GridSearchCV(knn,param_grid,cv=tscv,verbose=1)\n",
    "gsv.fit(X_train,y_train)\n",
    "print(\"Best HyperParameter: \",gsv.best_params_)\n",
    "print(\"Best Accuracy: %.2f%%\"%(gsv.best_score_*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Accuracy on Test data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=11,algorithm='kd_tree')\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\n",
    "print(\"Precision on test set: %0.3f\"%(precision_score(y_test, y_pred)))\n",
    "print(\"Recall on test set: %0.3f\"%(recall_score(y_test, y_pred)))\n",
    "print(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix of test set:\\n [ [TN  FP]\\n [FN TP] ]\\n\")\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## bi-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Breaking into Train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_sample['CleanedText'].values,df_sample['Score'].values,test_size=0.3,shuffle=False)\n",
    "\n",
    "#taking one words and two consecutive words together\n",
    "bi_gram = CountVectorizer(ngram_range=(1,2)) \n",
    "X_train = bi_gram.fit_transform(X_train)\n",
    "#Normalize Data\n",
    "X_train = preprocessing.normalize(X_train)\n",
    "print(\"Train Data Size: \",X_train.shape)\n",
    "X_test = bi_gram.transform(X_test)\n",
    "#Normalize Data\n",
    "X_test = preprocessing.normalize(X_test)\n",
    "print(\"Test Data Size: \",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.Brute Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(algorithm='brute')\n",
    "# neigh = np.arange(1,100,2)\n",
    "param_grid = {'n_neighbors':np.arange(1,100,2)} #params we need to try on classifier\n",
    "tscv = TimeSeriesSplit(n_splits=10) #For time based splitting\n",
    "gsv = GridSearchCV(knn,param_grid,cv=tscv,verbose=1)\n",
    "gsv.fit(X_train,y_train)\n",
    "print(\"Best HyperParameter: \",gsv.best_params_)\n",
    "print(\"Best Accuracy: %.2f%%\"%(gsv.best_score_*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Accuracy on Test data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=17)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\n",
    "print(\"Precision on test set: %0.3f\"%(precision_score(y_test, y_pred)))\n",
    "print(\"Recall on test set: %0.3f\"%(recall_score(y_test, y_pred)))\n",
    "print(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix of test set:\\n [ [TN  FP]\\n [FN TP] ]\\n\")\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Kd tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(algorithm='kd_tree')\n",
    "# neigh = np.arange(1,100,2)\n",
    "param_grid = {'n_neighbors':np.arange(1,100,2)} #params we need to try on classifier\n",
    "tscv = TimeSeriesSplit(n_splits=10) #For time based splitting\n",
    "gsv = GridSearchCV(knn,param_grid,cv=tscv,verbose=1)\n",
    "gsv.fit(X_train,y_train)\n",
    "print(\"Best HyperParameter: \",gsv.best_params_)\n",
    "print(\"Best Accuracy: %.2f%%\"%(gsv.best_score_*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Accuracy on Test data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=17,algorithm='kd_tree')\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\n",
    "print(\"Precision on test set: %0.3f\"%(precision_score(y_test, y_pred)))\n",
    "print(\"Recall on test set: %0.3f\"%(recall_score(y_test, y_pred)))\n",
    "print(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix of test set:\\n [ [TN  FP]\\n [FN TP] ]\\n\")\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Breaking into Train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_sample['CleanedText'].values,df_sample['Score'].values,test_size=0.3,shuffle=False)\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2)) #Using bi-grams\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "#Normalize Data\n",
    "X_train = preprocessing.normalize(X_train)\n",
    "print(\"Train Data Size: \",X_train.shape)\n",
    "X_test = tfidf.transform(X_test)\n",
    "#Normalize Data\n",
    "X_test = preprocessing.normalize(X_test)\n",
    "print(\"Test Data Size: \",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.Brute Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(algorithm='brute')\n",
    "# neigh = np.arange(1,100,2)\n",
    "param_grid = {'n_neighbors':np.arange(1,100,2)} #params we need to try on classifier\n",
    "tscv = TimeSeriesSplit(n_splits=10) #For time based splitting\n",
    "gsv = GridSearchCV(knn,param_grid,cv=tscv,verbose=1)\n",
    "gsv.fit(X_train,y_train)\n",
    "print(\"Best HyperParameter: \",gsv.best_params_)\n",
    "print(\"Best Accuracy: %.2f%%\"%(gsv.best_score_*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Accuracy on Test data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\n",
    "print(\"Precision on test set: %0.3f\"%(precision_score(y_test, y_pred)))\n",
    "print(\"Recall on test set: %0.3f\"%(recall_score(y_test, y_pred)))\n",
    "print(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix of test set:\\n [ [TN  FP]\\n [FN TP] ]\\n\")\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Kd tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(algorithm='kd_tree')\n",
    "# neigh = np.arange(1,100,2)\n",
    "param_grid = {'n_neighbors':np.arange(1,100,2)} #params we need to try on classifier\n",
    "tscv = TimeSeriesSplit(n_splits=10) #For time based splitting\n",
    "gsv = GridSearchCV(knn,param_grid,cv=tscv,verbose=1)\n",
    "gsv.fit(X_train,y_train)\n",
    "print(\"Best HyperParameter: \",gsv.best_params_)\n",
    "print(\"Best Accuracy: %.2f%%\"%(gsv.best_score_*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Accuracy on Test data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=9,algorithm='kd_tree')\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\n",
    "print(\"Precision on test set: %0.3f\"%(precision_score(y_test, y_pred)))\n",
    "print(\"Recall on test set: %0.3f\"%(recall_score(y_test, y_pred)))\n",
    "print(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix of test set:\\n [ [TN  FP]\\n [FN TP] ]\\n\")\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim\n",
    "Gensim is a robust open-source vector space modeling and topic modeling toolkit implemented in Python. It uses NumPy, SciPy and optionally Cython for performance. Gensim is specifically designed to handle large text collections, using data streaming and efficient incremental algorithms, which differentiates it from most other scientific software packages that only target batch and in-memory processing.\n",
    "\n",
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#Loading the model from file in the disk\n",
    "w2vec_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_vocub = w2vec_model.wv.vocab\n",
    "len(w2v_vocub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avg Word2Vec\n",
    "One of the most naive but good ways to convert a sentence into a vector\n",
    "Convert all the words to vectors and then just take the avg of the vectors the resulting vector represent the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "avg_vec_google = [] #List to store all the avg w2vec's \n",
    "# no_datapoints = 364170\n",
    "# sample_cols = random.sample(range(1, no_datapoints), 20001)\n",
    "for sent in df_sample['CleanedText_NoStem']:\n",
    "    cnt = 0 #to count no of words in each reviews\n",
    "    sent_vec = np.zeros(300) #Initializing with zeroes\n",
    "#     print(\"sent:\",sent) \n",
    "    sent = sent.decode(\"utf-8\") \n",
    "    for word in sent.split():\n",
    "        try:\n",
    "#             print(word)\n",
    "            wvec = w2vec_model.wv[word] #Vector of each using w2v model\n",
    "#             print(\"wvec:\",wvec)\n",
    "            sent_vec += wvec #Adding the vectors\n",
    "#             print(\"sent_vec:\",sent_vec)\n",
    "            cnt += 1\n",
    "        except: \n",
    "            pass #When the word is not in the dictionary then do nothing  \n",
    "#     print(sent_vec)\n",
    "    sent_vec /= cnt #Taking average of vectors sum of the particular review\n",
    "#     print(\"avg_vec:\",sent_vec)\n",
    "    avg_vec_google.append(sent_vec) #Storing the avg w2vec's for each review\n",
    "#     print(\"*******************************************************************\")\n",
    "# print(avg_vec_google)\n",
    "avg_vec_google = np.array(avg_vec_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(avg_vec_google).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "avg_vec_norm = preprocessing.normalize(avg_vec_google)\n",
    "\n",
    "#Not shuffling the data as we want it on time basis\n",
    "X_train, X_test, y_train, y_test = train_test_split(avg_vec_norm,df_sample['Score'].values,test_size=0.3,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_vec_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_vec_norm.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.Brute Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(algorithm='brute')\n",
    "# neigh = np.arange(1,100,2)\n",
    "param_grid = {'n_neighbors':np.arange(1,40,2)} #params we need to try on classifier\n",
    "tscv = TimeSeriesSplit(n_splits=10) #For time based splitting\n",
    "gsv = GridSearchCV(knn,param_grid,cv=tscv,verbose=1)\n",
    "gsv.fit(X_train,y_train)\n",
    "print(\"Best HyperParameter: \",gsv.best_params_)\n",
    "print(\"Best Accuracy: %.2f%%\"%(gsv.best_score_*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Accuracy on Test data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\n",
    "print(\"Precision on test set: %0.3f\"%(precision_score(y_test, y_pred)))\n",
    "print(\"Recall on test set: %0.3f\"%(recall_score(y_test, y_pred)))\n",
    "print(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix of test set:\\n [ [TN  FP]\\n [FN TP] ]\\n\")\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Kd tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(algorithm='kd_tree')\n",
    "# neigh = np.arange(1,100,2)\n",
    "param_grid = {'n_neighbors':np.arange(1,40,2)} #params we need to try on classifier\n",
    "tscv = TimeSeriesSplit(n_splits=10) #For time based splitting\n",
    "gsv = GridSearchCV(knn,param_grid,cv=tscv,verbose=1,n_jobs=-1)\n",
    "gsv.fit(X_train,y_train)\n",
    "print(\"Best HyperParameter: \",gsv.best_params_)\n",
    "print(\"Best Accuracy: %.2f%%\"%(gsv.best_score_*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Accuracy on Test data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=11,algorithm='kd_tree')\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\n",
    "print(\"Precision on test set: %0.3f\"%(precision_score(y_test, y_pred)))\n",
    "print(\"Recall on test set: %0.3f\"%(recall_score(y_test, y_pred)))\n",
    "print(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix of test set:\\n [ [TN  FP]\\n [FN TP] ]\\n\")\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf W2Vec\n",
    "1. Another way to covert sentence into vectors\n",
    "2. Take weighted sum of the vectors divided by the sum of all the tfidf's\n",
    "i.e. (tfidf(word) x w2v(word))/sum(tfidf's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "###Sorting as we want according to time series\n",
    "df_sample.sort_values('Time',inplace=True) \n",
    "\n",
    "###tf-idf with No Stemming\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2)) #Using bi-grams\n",
    "\n",
    "tfidf_vec_new = tfidf.fit_transform(df_sample['CleanedText_NoStem'].values)\n",
    "\n",
    "print(tfidf_vec_new.shape)\n",
    "\n",
    "features = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tfidf_w2v_vec_google = []\n",
    "review = 0\n",
    "\n",
    "for sent in df_sample['CleanedText_NoStem'].values:\n",
    "    cnt = 0 \n",
    "    weighted_sum  = 0\n",
    "    sent_vec = np.zeros(300)\n",
    "    sent = sent.decode(\"utf-8\") \n",
    "    for word in sent.split():\n",
    "        try:\n",
    "#             print(word)\n",
    "            wvec = w2vec_model.wv[word] #Vector of each using w2v model\n",
    "#             print(\"w2vec:\",wvec)\n",
    "#             print(\"tfidf:\",tfidf_vec_ns[review,features.index(word)])\n",
    "            tfidf_vec = tfidf_vec_new[review,features.index(word)]\n",
    "            sent_vec += (wvec * tfidf_vec)\n",
    "            weighted_sum += tfidf_vec\n",
    "        except:\n",
    "#             print(review)\n",
    "            pass\n",
    "    sent_vec /= weighted_sum\n",
    "#     print(sent_vec)\n",
    "    tfidf_w2v_vec_google.append(sent_vec)\n",
    "    review += 1\n",
    "tfidf_w2v_vec_google = np.array(tfidf_w2v_vec_google)\n",
    "savetofile(tfidf_w2v_vec_google,\"tfidf_w2v_vec_google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precomputed File\n",
    "tfidf_w2v_vec_google = openfromfile(\"tfidf_w2v_vec_google\")\n",
    "#Loading the same samples as using precomuted file\n",
    "df_sample_new = openfromfile(\"df_sample_new_tfidfw2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidfw2v_vecs_norm = preprocessing.normalize(tfidf_w2v_vec_google)\n",
    "\n",
    "#Not shuffling the data as we want it on time basis\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidfw2v_vecs_norm,df_sample_new['Score'].values,test_size=0.3,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.Brute Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "knn = KNeighborsClassifier(algorithm='brute')\n",
    "# neigh = np.arange(1,100,2)\n",
    "param_grid = {'n_neighbors':np.arange(1,40,2)} #params we need to try on classifier\n",
    "tscv = TimeSeriesSplit(n_splits=10) #For time based splitting\n",
    "gsv = GridSearchCV(knn,param_grid,cv=tscv,verbose=1)\n",
    "gsv.fit(X_train,y_train)\n",
    "print(\"Best HyperParameter: \",gsv.best_params_)\n",
    "print(\"Best Accuracy: %.2f%%\"%(gsv.best_score_*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Accuracy on Test data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\n",
    "print(\"Precision on test set: %0.3f\"%(precision_score(y_test, y_pred)))\n",
    "print(\"Recall on test set: %0.3f\"%(recall_score(y_test, y_pred)))\n",
    "print(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix of test set:\\n [ [TN  FP]\\n [FN TP] ]\\n\")\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Kd tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "knn = KNeighborsClassifier(algorithm='kd_tree')\n",
    "# neigh = np.arange(1,100,2)\n",
    "param_grid = {'n_neighbors':np.arange(1,40,2)} #params we need to try on classifier\n",
    "tscv = TimeSeriesSplit(n_splits=10) #For time based splitting\n",
    "gsv = GridSearchCV(knn,param_grid,cv=tscv,verbose=1)\n",
    "gsv.fit(X_train,y_train)\n",
    "print(\"Best HyperParameter: \",gsv.best_params_)\n",
    "print(\"Best Accuracy: %.2f%%\"%(gsv.best_score_*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Accuracy on Test data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\n",
    "print(\"Precision on test set: %0.3f\"%(precision_score(y_test, y_pred)))\n",
    "print(\"Recall on test set: %0.3f\"%(recall_score(y_test, y_pred)))\n",
    "print(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix of test set:\\n [ [TN  FP]\\n [FN TP] ]\\n\")\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "Note: As I have taken only 25k points(due to huge training time) the accuracy will not be the representive of the real accuracy\n",
    "\n",
    "1. Best Accuracy of 85.107% is achieved by Avg Word2Vec Featurization\n",
    "2. The kd-tree and brute implementation of KNN gives relatively similar results\n",
    "3. KNN is a very slow Algorithm compared to others takes alot of time to train\n",
    "4. KNN did not fair in terms of precision and F1-score. Overall KNN was not that good for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
